## 2.13 Raster data in PostGIS (demo)
The advancement in movement ecology from a data perspective can reach its full potential only by combining the technology of animal tracking with the technology of other environmental sensing programmes. Ecology is fundamentally spatial, and animal ecology is obviously no exception. Any scientific question in animal ecology cannot overlook the dynamic interaction between individual animals or populations, and the environment in which the ecological processes occur. Movement provides the mechanistic link to explain this complex ecosystem interaction, as the movement path is dynamically determined by external factors, through their effect on the individual's state and the life-history characteristics of an animal. Therefore, most modelling approaches for animal movement include environmental factors as explanatory variables.  

PostGIS is able to store, manage and process raster layer, as it does with vectors. There is a large set of functionalities available. While dedicated image processing tools can be more efficient than PostGIS and with a wider set of tools, storing raster in a database (as in-db or out-db raster) have advantages in terms of data management and integration between raster, vector and tabular data that are joined in a single environment and processed with (spatial) SQL.

### DEMONSTRATION 1: Analyzing movement data with a (raster) environmental layer
In these examples we will explore some simple analysis performed with spatial SQL into our GPS tracking with **land cover/use data** derived from [CORINE land cover database](https://land.copernicus.eu/pan-european/corine-land-cover) (as a static raster layer). 
#### Set up raster layer into the database
The primary method to import a raster layer is the command-line tool **[raster2pgsql](http://postgis.net/docs/using_raster_dataman.html)**, the equivalent of shp2pgsql but for raster files, that converts GDAL-supported rasters into SQL suitable for loading into PostGIS. It is also capable of loading folders of raster files. **[GDAL](http://www.gdal.org/)** (Geospatial Data Abstraction Library) is a (free) library for reading, writing and processing raster geospatial data formats. It has a lot of simple but very powerful and fast command-line tools for raster data translation and processing. The related OGR library provides a similar capability for simple vector data features. GDAL is used by most of the spatial open-source tools and by a large number of commercial software programs as well. You will probably benefit in particular from the tools *gdalinfo* (get a layer's basic metadata), *gdal\_translate* (change data format, change data type, cut), gdalwarp1 (mosaicing, reprojection and warping utility).

An interesting feature of *raster2pgsql* is its capability to store the rasters inside the database (in-db) or keep them as (out-db) files in the file system (with the raster2pgsql -R option). In the last case, only raster metadata are stored in the database, not pixel values themselves. Loading out-db rasters metadata is much faster than loading them completely in the database. Most operations at the pixel values level (e.g. \*ST\_SummaryStats\*) will have equivalent performance with out- and in-db rasters. Other functions, like *ST\_Tile*, involving only the metadata, will be faster with out-db rasters. Another advantage of out-db rasters is that they stay accessible for external applications unable to query databases (with SQL). However, the administrator must make sure that the link between what is in the db (the path to the raster file in the file system) is not broken (e.g. by moving or renaming the files). On the other hand, only in-db rasters can be generated with CREATE TABLE and modified with UPDATE statements. Which is the best choice depends on the size of the data set and on considerations about performance and database management. A good practice is generally to load very large raster data sets as out-db and to load smaller ones as in-db to save time on loading and to avoid repeatedly backing up huge, static rasters.

The QGIS plugin *Load Raster to PostGIS* can also be used to import raster data with a graphical interface. An important parameter to set when importing raster layers is the number of tiles (*-t* option). Tiles are small subsets of the image and correspond to a physical record in the table. This approach dramatically decreases the time required to retrieve information. The recommended values for the tile option range from 20x20 to 100x100. Here is the code (to be run in the Command Prompt) to transform a raster (the digital elevation model derived from SRTM) into the SQL code that is then used to physically load the raster into the database (as you did with *shp2pgsql* for vectors):

We will use two raster in this exercise: 
* land cover (source: [Corine](http://www.eea.europa.eu/data-and-maps/data/corine-land-cover-2006-clc2006-100-m-version-12-2009)) 
* digital elevation models (source: [SRTM](http://srtm.csi.cgiar.org/), see also *Jarvis A, Reuter HI, Nelson A, Guevara E (2008) Hole-filled seamless SRTM data V4. International Centre for Tropical Agriculture (CIAT)*).

You import the digital elevation model:

```
> "C:\PostgreSQL\9.6\bin\raster2pgsql.exe" -I -M -C -s 4326 -t 20x20 C:\tracking_db\data\env_data\raster\srtm_dem.tif env_data.srtm_dem | "C:\Program Files\PostgreSQL\9.6\bin\psql.exe" -p 5432 -d gps_tracking_db -U postgres -h localhost
```

Meaning of raster2pgsql parameters:
* -C: new table
* -t: divide the images in tiles
* -M: vacuum analyze the raster table
* -I: create an index
* -s: specify the reference system

If you copy-paste the copy from an Internet browser, some character (e.g. double quotes and 'x') might be transformed into different character and you might have to manually fix this problem). You can repeat the same process on the land cover layer:

```
> "C:\PostgreSQL\9.6\bin\raster2pgsql.exe" -I -M -C -s 3035 C:\tracking_db\data\env_data\raster\corine06.tif -t 20x20 env_data.corine_land_cover | "C:\Program Files\PostgreSQL\9.6\bin\psql.exe" -p 5432 -d gps_tracking_db -U postgres -h localhost
```

The reference system of the Corine Land Cover data set is not geographic coordinates (SRID 4326), but ETRS89/ETRS-LAEA (SRID 3035), an equal-area projection over Europe. This must be specified with the -s option and kept in mind when this layer will be connected to other spatial layers stored in a different reference system. As with shp2pgsql.exe, the -I option will create a spatial index on the loaded tiles, speeding up many spatial operations, and the*-C* option will generate a set of constraints on the table, allowing it to be correctly listed in the *raster\_columns* metadata table. The land cover raster identifies classes that are labeled by a code (an integer). To specify the meaning of the codes, you can add a table where they are described. In this example, the land cover layer is taken from the Corine project. Classes are described by a hierarchical legend over three nested levels. The legend is provided in the test data set in the file *corine\_legend.csv*. You import the table of the legend (first creating an empty table, and then loading the data):

```sql
CREATE TABLE env_data.corine_land_cover_legend(
  grid_code integer NOT NULL,
  clc_l3_code character(3),
  label1 character varying,
  label2 character varying,
  label3 character varying,
  CONSTRAINT corine_land_cover_legend_pkey 
    PRIMARY KEY (grid_code ));
```

```sql
COMMENT ON TABLE env_data.corine_land_cover_legend
IS 'Legend of Corine land cover, associating the numeric code to the three nested levels.';
```

Then you load the data:

```sql
COPY env_data.corine_land_cover_legend 
FROM 
  'C:\tracking_db\data\env_data\raster\corine_legend.csv' 
  WITH (FORMAT csv, HEADER, DELIMITER ';');
```

You can retrieve a summary of the information from all raster layers available in the database with the following command:

```sql
SELECT * FROM raster_columns;
```

#### Create a table for land cover raster data from an existing (larger) DB layer (clip)
```sql
CREATE TABLE env_data.land_cover (rid SERIAL primary key, rast raster);

CREATE INDEX land_cover_rast_idx 
  ON env_data.land_cover 
  USING GIST (ST_ConvexHull(rast));
```
```sql
INSERT INTO env_data.land_cover (rast)
SELECT 
  rast
FROM 
  env_data.corine_land_cover, 
  env_data.study_area
WHERE 
  st_intersects(rast, ST_Expand(st_transform(geom, 3035), 5000)) AND 
  study_areas_id = 1;
```
```sql
SELECT AddRasterConstraints('env_data'::name, 'land_cover'::NAME, 'rast'::name);
```

#### Export the layer to tiff
Create a new table with all raster unioned, add constraints, export to TIFF with GDAL, drop the table
```sql
CREATE TABLE env_data.land_cover_export(rast raster);
```
```sql
INSERT INTO 
  env_data.land_cover_export
SELECT 
  st_union(rast) AS rast 
FROM 
  env_data.land_cover;
```
```sql
SELECT AddRasterConstraints('env_data'::name, 'land_cover_export'::name, 'rast'::name);
```
Export with GDAL_translate  

```
> gdal_translate -of GTIFF "PG:host=eurodeer2.fmach.it dbname=eurodeer_db user='postgres' schema=env_data table=land_cover_export mode=2" C:\Users\User\Desktop\landcover\land_cover.tif
```

Remove the unioned table
```sql
DROP TABLE env_data.land_cover_export;
```

#### Intersect the fixes with the land cover layer for the animal 782
```sql
SELECT  
  st_value(rast,st_transform(geom, 3035)) as lc_id
FROM 
  main.gps_data_animals,
  env_data.land_cover
WHERE
  animals_id = 782 AND
  gps_validity_code = 1 AND
  st_intersects(st_transform(geom, 3035), rast);
```
#### Calculate the percentage of each land cover class for fixes of the animal 782
```sql
WITH locations_landcover AS 
(
SELECT  
  st_value(rast,st_transform(geom, 3035)) AS lc_id
FROM 
  main.gps_data_animals,
  env_data.land_cover
 WHERE
  animals_id = 782 AND
  gps_validity_code = 1 AND
  st_intersects(st_transform(geom, 3035), rast)
)
SELECT
  lc_id,
  label3,
  (count(*) * 1.0 / (SELECT count(*) FROM locations_landcover))::numeric(5,4) AS percentage
FROM 
  locations_landcover,
  env_data.corine_land_cover_legend
WHERE
  grid_code = lc_id
GROUP BY 
  lc_id,
  label3
ORDER BY
  percentage DESC;
```
Now we can start to play with the data. For users, the data type (vector, raster) used to store spatial information is not so relevant when they query their data: queries should transparently use any kind of spatial data as input. Users can then focus on the environmental model instead of worrying about the data model. In the next example, you intersect a point with two raster layers (altitude and land cover) in the same way you do for vector layers. In the case of land cover, the point must first be projected into the Corine reference system (SRID 3035). In the raster layer, just the Corine code class (integer) is stored while the legend is stored in the table *env\_data.corine\_land\_cover\_legend*. In the query, the code class is joined to the legend table and the code description is returned. This is an example of integration of both spatial and non-spatial elements in the same query.

#### Intersect the convex hull of animal 782 with the land cover layer
```sql
SELECT 
  (stats).value AS grid_code, 
  (stats).count AS num_pixels
FROM 
  (
  SELECT
    ST_valuecount(ST_union(st_clip(rast ,st_transform(geom,3035)))) AS stats
  FROM
    env_data.view_convexhull,
    env_data.land_cover
  WHERE
    animals_id = 782 AND
    st_intersects (rast, st_transform(geom,3035))
  ) a
```

#### Calculate the percentage of each land cover class in the convex hull for the animal 782
```sql
WITH convexhull_landcover AS 
(
SELECT 
  (stats).value AS lc_id, 
  (stats).count AS num_pixels
FROM 
  (
  SELECT
    ST_valuecount(ST_union(st_clip(rast ,st_transform(geom,3035))))  stats
  FROM
    env_data.view_convexhull,
    env_data.land_cover
  WHERE
    animals_id = 782 AND
    st_intersects (rast, st_transform(geom,3035))
  ) AS a
)
SELECT
  lc_id,
  label3,
  (num_pixels * 1.0 / (sum(num_pixels)over()))::numeric(5,4) AS percentage
FROM 
  convexhull_landcover,
  env_data.corine_land_cover_legend
WHERE
  grid_code = lc_id
ORDER BY
  percentage DESC;
```

#### Intersect the fixes for males vs female with the land cover layer
```sql
SELECT
  sex,  
  ST_Value(rast, ST_Transform(geom, 3035)) AS lc_id,
  count(*) AS number_locations
FROM 
  env_data.gps_data_animals,
  env_data.land_cover,
  main.animals
WHERE
  animals.animals_id = gps_data_animals.animals_id AND
  gps_validity_code = 1 AND
  ST_Intersects(ST_Transform(geom, 3035), rast)
GROUP BY 
  sex, lc_id
ORDER BY 
  lc_id;
```

#### Calculate the percentage of different land cover classes for all the monthly convex hulls of the animal 782
```sql
WITH convexhull_landcover AS
(
SELECT 
  months,
  (stats).value AS lc_id, 
  (stats).count AS num_pixels
FROM (
  SELECT 
    months, 
    ST_ValueCount(ST_Union(ST_Clip(rast ,ST_Transform(geom,3035))))  stats
  FROM
    env_data.view_convexhull_monthly,
    env_data.land_cover
  WHERE
    ST_Intersects (rast, ST_Transform(geom,3035))
  GROUP BY 
    months) a
)
SELECT
  months,
  label3,
  (num_pixels * 1.0 / (sum(num_pixels) over (PARTITION BY months)))::numeric(5,4) AS percentage
FROM 
  convexhull_landcover,
  env_data.corine_land_cover_legend
WHERE
  grid_code = lc_id
ORDER BY
  label3, months;
```

#### Calculate the percentage of each land cover class for male/female *(takes a bit)*
```sql
WITH locations_landcover AS
(
SELECT
  sex,  
  st_value(rast,st_transform(geom, 3035)) AS lc_id,
  count(*) AS number_locations
FROM 
  env_data.gps_data_animals,
  env_data.land_cover,
  main.animals
 WHERE
  animals.animals_id = gps_data_animals.animals_id AND
  gps_validity_code = 1 AND
  st_intersects(st_transform(geom, 3035), rast)
GROUP BY sex, lc_id
) 
SELECT
  sex,
  label3,
  (number_locations *1.0 / sum(number_locations) OVER (partition by sex))::numeric(5,4) AS percentage
FROM 
  locations_landcover,
  env_data.corine_land_cover_legend
WHERE
  grid_code = lc_id 
ORDER BY
  label3, sex;
```

### DEMONSTRATION 2: Analyzing location data with a time series of environmental layers

Animal locations are not only spatial, but are fully defined by spatial and temporal coordinates (as given by the acquisition time). Logically, the same temporal definition also applies to environmental layers. Some characteristics of the landscape, such as land cover or road networks, can be considered static over a large period of time and these environmental layers are commonly intersected with animal locations to infer habitat use and selection by animals. However, many characteristics actually relevant to wildlife, such as vegetation biomass or road traffic, are indeed subject to temporal variability (on the order of hours to weeks) in the landscape, and would be better represented by dynamic layers that correspond closely to the conditions actually encountered by an animal moving across the landscape. Nowadays, satellite-based remote sensing can provide high temporal resolution global coverage of medium/high-resolution images that can be used to compute a large number of environmental parameters very useful to wildlife studies. One of the most common set of environmental data time series is the Normalized Difference Vegetation Index (NDVI), but other examples include data sets on snow, ocean primary productivity, surface temperature, or salinity. Snow cover, NDVI, and sea surface temperature are some examples of indexes that can be used as explanatory variables in statistical models or to parametrize bayesian inferences or mechanistic models. The main shortcoming of such remote-sensing layers is the relatively low spatial and/or temporal resolution, which does not fit the current average bias of wildlife-tracking GPS locations (less than 20 m) and temporal scale of animal movement, thus potentially leading to a mismatch between the animal-based information and the environmental layers (note that the resolution can still be perfectly fine, depending on the overall spatial and temporal variability and the species and biological process under study). Higher-resolution images and new types of information (e.g. forest structure) are presently provided by new types of sensors, such as those from lidar, radar, or hyper-spectral remote-sensing technology and Sentinel 2 (optical data). The new generation of satellites requires dedicated storage and analysis tools (e.g. Goggle Earth Engine) that can be related to the Big Data framework. 
Here, we will explore some simple example of spatio-temporal analyses that involve the interaction between GPS data and NDVI time series.

The MODIS (Moderate Resolution Imaging Spectroradiometer) instrument operates on the NASA's Terra and Aqua spacecraft. The instrument views the entire earth surface every 1 to 2 days, captures data in 36 spectral bands ranging in wavelength from 0.4 μm to 14.4 μm and at varying spatial resolutions (250 m, 500 m and 1 km). The Global MODIS vegetation indices (code MOD13Q1) are designed to provide consistent spatial and temporal comparisons of vegetation conditions. Red and near-infrared reflectances, centred at 645 nm and 858 nm, respectively, are used to determine the daily vegetation indices, including the well known NDVI. This index is calculated by contrasting intense chlorophyll pigment absorption in the red against the high reflectance of leaf mesophyll in the near infrared. It is a proxy of plant photosynthetic activity and has been found to be highly related to green leaf area index (LAI) and to the fraction of photosynthetically active radiation absorbed by vegetation (FAPAR). Past studies have demonstrated the potential of using NDVI data to study vegetation dynamics. More recently, several applications have been developed using MODIS NDVI data such as land-cover change detection, monitoring forest phenophases, modelling wheat yield, and other applications in forest and agricultural sciences. However, the utility of the MODIS NDVI data products is limited by the availability of high-quality data (e.g. cloud-free), and several processing steps are required before using the data: acquisition via web facilities, re-projection from the native sinusoidal projection to a standard latitude-longitude format, eventually the mosaicking of two or more tiles into a single tile. A number of processing techniques to 'smooth' the data and obtain a cleaned (no clouds) time series of NDVI imagery have also been implemented. These kind of processes are usually based on a set of ancillary information on the data quality of each pixel that are provided together with MODIS NDVI.

NDVI data source used in these exercises: MODIS NDVI (http://modis-land.gsfc.nasa.gov/vi.html), in a version (smoothed, weekly) downloaded from [Boku University Portal](http://ivfl-info.boku.ac.at/index.php/eo-data-processing).

#### Import MODIS NDVI time series *(only example, not run)*

`raster2pgsql.exe -C -r -t 128x128 -F -M -R -N -3000 C:/tracking_db/data/env_data/raster/MOD*.tif env_data.ndvi_modis | psql.exe -d eurodeer_db -U postgres -p 5432`

Meaning of raster2pgsql parameters
* -R: out of db raster
* -F: add a column with the name of the file
* -N: set the null value

#### Create and fill a field to explicitly mark the reference date of the images
Structure of the name of the original file:  *MCD13Q1.A2005003.005.250m_7_days_NDVI.REFMIDw.tif*  
Date must be extracted from the name and stored with a proper data type so that it can be queried with functions related to time.

```sql
ALTER TABLE env_data.ndvi_modis ADD COLUMN acquisition_date date;
UPDATE 
  env_data.ndvi_modis 
SET 
  acquisition_date = to_date(substring(filename FROM 10 FOR 7), 'YYYYDDD');
```
```sql
CREATE INDEX ndvi_modis_referemce_date_index
  ON env_data.ndvi_modis
  USING btree
  (acquisition_date);
```
#### Create a table from an existing DB layer with a larger - MODIS NDVI
```sql
CREATE TABLE env_data.modis_ndvi(
  rid serial PRIMARY KEY,
  rast raster,
  filename text,
  acquisition_date date);
```
```sql
INSERT INTO env_data.modis_ndvi (rast, filename, acquisition_date)
SELECT 
  rast, 
  filename, 
  acquisition_date
FROM
  env_data_ts.ndvi_modis_boku, 
  main.study_areas
WHERE 
  st_intersects(rast, ST_Expand(geom, 0.05)) AND 
  study_areas_id = 1;
```
```sql
SELECT AddRasterConstraints('env_data'::name, 'modis_ndvi'::NAME, 'rast'::name);
```
```sql
CREATE INDEX modis_ndvi_rast_idx 
  ON env_data.modis_ndvi
  USING GIST (ST_ConvexHull(rast));
```
```sql
CREATE INDEX modis_ndvi_referemce_date_index
  ON env_data.modis_ndvi
  USING btree
  (acquisition_date);
```

#### Extraction of a NDVI value for a point/time
```sql
WITH pointintime AS 
(
SELECT 
  ST_SetSRID(ST_MakePoint(11.1, 46.1), 4326) AS geom, 
  '2005-01-03'::date AS reference_date
)
SELECT 
  ST_Value(rast, geom) * 0.0048 -0.2 AS ndvi
FROM 
  env_data.modis_ndvi,
  pointintime
WHERE 
  ST_Intersects(geom, rast) AND
  modis_ndvi.acquisition_date = pointintime.reference_date;
```

#### Extraction of a NDVI time series of values of a given fix
```sql
SELECT 
  ST_X(geom) AS x,
  ST_Y(geom) AS y,
  acquisition_date,
  ST_Value(rast, geom) * 0.0048 -0.2 AS ndvi
FROM 
  env_data.modis_ndvi,
  env_data.gps_data_animals
WHERE 
  ST_Intersects(geom, rast) AND
  gps_data_animals_id = 1
ORDER BY 
  acquisition_date;
```

#### Extraction of the NDVI value for a fix as temporal interpolation of the 2 closest images
```sql
SELECT 
  gps_data_animals_id, 
  acquisition_time,
  DATE_TRUNC('week', acquisition_time::date)::date,
  (trunc(
    (
    ST_VALUE(pre.rast, geom) * 
    (DATE_TRUNC('week', acquisition_time::date + 7)::date - acquisition_time::date)::integer 
    +
    ST_VALUE(post.rast, geom) * 
    (acquisition_time::date - DATE_TRUNC('week', acquisition_time::date)::date))::integer/7)
    ) * 0.0048 -0.2 AS ndvi
FROM  
  env_data.gps_data_animals,
  env_data.modis_ndvi AS pre,
  env_data.modis_ndvi AS post
WHERE
  ST_INTERSECTS(geom, pre.rast) AND 
  ST_INTERSECTS(geom, post.rast) AND 
  DATE_TRUNC('week', acquisition_time::date)::date = pre.acquisition_date AND 
  DATE_TRUNC('week', acquisition_time::date + 7)::date = post.acquisition_date AND
  gps_validity_code = 1 AND
  gps_data_animals_id = 2;
```

#### Extraction of the NDVI values for a set of fixes as temporal interpolation of the 2 closest images for animal 782
```sql
SELECT 
  gps_data_animals_id, 
  ST_X(geom)::numeric (8,5) AS x,
  ST_Y(geom)::numeric (8,5) AS y,
  acquisition_time,
  DATE_TRUNC('week', acquisition_time::date)::date,
  (trunc(
    (
    ST_VALUE(pre.rast, geom) * 
    (DATE_TRUNC('week', acquisition_time::date + 7)::date - acquisition_time::date)::integer 
    +
    ST_VALUE(post.rast, geom) * 
    (acquisition_time::date - DATE_TRUNC('week', acquisition_time::date)::date))::integer/7)
    ) * 0.0048 -0.2
FROM  
  env_data.gps_data_animals,
  env_data.modis_ndvi AS pre,
  env_data.modis_ndvi AS post
WHERE
  ST_INTERSECTS(geom, pre.rast) AND 
  ST_INTERSECTS(geom, post.rast) AND 
  DATE_TRUNC('week', acquisition_time::date)::date = pre.acquisition_date AND 
  DATE_TRUNC('week', acquisition_time::date + 7)::date = post.acquisition_date AND
  gps_validity_code = 1 AND
  animals_id = 782
ORDER by 
  acquisition_time;
```

#### Calculate average, max and min NDVI for the minimum convex hull of a every month for animal 782
```sql
SELECT
  months, 
  (stats).mean  * 0.0048 - 0.2 AS ndvi_avg,
  (stats).min * 0.0048 - 0.2 AS ndvi_min,
  (stats).max * 0.0048 - 0.2 AS ndvi_max
FROM
( 
  SELECT
    months,
    ST_SummaryStats(ST_UNION(ST_CLIP(rast,geom), 'max'))  AS stats
  FROM 
    env_data.view_convexhull_monthly,
    env_data.modis_ndvi
  WHERE
    ST_INTERSECTS (rast, geom) AND 
    EXTRACT(month FROM acquisition_date) = months AND
    months IN (1,2,3)
  GROUP BY months
  ORDER BY months
) a;
```

#### Calculate time series of average, max and min NDVI for a given polygon in a given time interval
```sql 
WITH selected_area AS 
(SELECT st_setsrid(ST_MakePolygon(ST_GeomFromText('LINESTRING(11.03 45.98, 11.03 46.02, 11.08 46.02, 11.08 45.98, 11.03 45.98)')), 4326) AS geom)
SELECT
  acquisition_date, 
  ((stats).mean  * 0.0048 - 0.2)::numeric (4,3)  AS ndvi_avg,
  ((stats).min * 0.0048 - 0.2)::numeric (4,3)  AS ndvi_min,
  ((stats).max * 0.0048 - 0.2)::numeric (4,3) AS ndvi_max,
  ((stats).stddev)::numeric (6,3) AS digital_value_stddev,
  ((stats).count) AS num_pixels
FROM
( 
  SELECT
    acquisition_date,
    ST_SummaryStats(ST_UNION(ST_CLIP(rast,geom)))  AS stats
  FROM 
    selected_area,
    env_data.modis_ndvi
  WHERE
    ST_INTERSECTS (rast, geom) AND 
    acquisition_date > '1/1/2017' and acquisition_date < '30/6/2017'
  GROUP BY acquisition_date
  ORDER BY acquisition_date
) a;
```
